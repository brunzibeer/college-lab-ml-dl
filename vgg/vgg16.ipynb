{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg16_sol.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9knEDxY-0vn"
      },
      "source": [
        "# Implement VGG-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By6XoRQyL_bN"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def conv3x3(in_channels: int, out_channels: int):\n",
        "    return nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                     kernel_size=3, padding=1)\n",
        "\n",
        "def max_pool_2d():\n",
        "    return nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "  \n",
        "class VGGlayer(nn.Module):\n",
        "  \n",
        "  def __init__(self, in_channels: int, out_channels: int, activated=True, \n",
        "              max_pool = False):\n",
        "        super(VGGlayer, self).__init__()\n",
        "      \n",
        "        layers = [\n",
        "            conv3x3(in_channels, out_channels),\n",
        "            nn.ReLU(True),\n",
        "        ] \n",
        "        \n",
        "        if max_pool:\n",
        "          layers += [max_pool_2d()]\n",
        "          \n",
        "        self.layer = nn.Sequential(*layers)\n",
        "  \n",
        "  def forward(self, x):\n",
        "      return self.layer(x)\n",
        "\n",
        "\n",
        "class VGG16(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels: int = 3, num_classes: int = 1000):\n",
        "        super(VGG16, self).__init__()\n",
        "\n",
        "        self.conv_features = nn.Sequential(\n",
        "            VGGlayer(in_channels, 64),\n",
        "            VGGlayer(64, 64, max_pool=True),\n",
        "            VGGlayer(64, 128),\n",
        "            VGGlayer(128, 128, max_pool=True),\n",
        "            VGGlayer(128, 256),\n",
        "            VGGlayer(256, 256),\n",
        "            VGGlayer(256, 256, max_pool=True),\n",
        "            VGGlayer(256, 512),\n",
        "            VGGlayer(512, 512),\n",
        "            VGGlayer(512, 512, max_pool=True),\n",
        "            VGGlayer(512, 512),\n",
        "            VGGlayer(512, 512),\n",
        "            VGGlayer(512, 512, max_pool=True)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGj9ISKL-5hZ"
      },
      "source": [
        "# Forward Pass Debug\n",
        "If it can process random data, then you're mostly alright :D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIFRGVCaMeY7"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "net = VGG16()\n",
        "X = torch.rand((8, 3, 224, 224))\n",
        "num_params = sum([np.prod(p.shape) for p in net.parameters()])\n",
        "\n",
        "print(f\"Number of parameters : {num_params}\")\n",
        "print('-'*50)\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLlCXtaH_Lrc"
      },
      "source": [
        "# Let's train on CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAX1THll-IgS"
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "mean = (0.4913997551666284, 0.48215855929893703, 0.4465309133731618)\n",
        "std  = (0.24703225141799082, 0.24348516474564, 0.26158783926049628)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Resize((224,224)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean, std)])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True, num_workers=8)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=False, num_workers=8)\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXeHsX_I_veV"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img * np.array(std)[:,None,None] + np.array(mean)[:,None,None] # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "images, labels = images[:4], labels[:4]\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7w-ZoDu_ZKd"
      },
      "source": [
        "assert torch.cuda.is_available(), \"Notebook is not configured properly!\"\n",
        "device = 'cuda:0'\n",
        "\n",
        "net = VGG16(num_classes=10).to(device)\n",
        "crit = nn.CrossEntropyLoss()\n",
        "opt = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "epochs = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guB8cNEkKAp4"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNn2W2ZLKSf9"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "now = datetime.now()\n",
        "train_name = f'{now.hour}:{now.minute}:{now.second}/'\n",
        "writer = SummaryWriter('./logs/' + train_name)\n",
        "\n",
        "for e in range(epochs):\n",
        "  for i, (x, y) in enumerate(tqdm(trainloader)):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    y_pred = net(x)\n",
        "    loss = crit(y_pred, y)\n",
        "    # write value on Tensorboard\n",
        "    if i % 50 == 0:\n",
        "      writer.add_scalar('Loss/train', loss.cpu().item(), i + e * len(trainloader))\n",
        "    \n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "  corr = 0\n",
        "  for x, y in testloader:\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    y_pred = net(x)\n",
        "    corr += (torch.max(y_pred, 1)[1] == y).sum()\n",
        "  print(f\"Accuracy for epoch {e}:{corr / len(testset)}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}